arch: ResNet50

# ===== Dataset ===== #
data: /s/babbage/b/nobackup/nblancha/public-datasets/subnetworks/
set: ImageNet
name: biprop

# ===== Learning Rate Policy ======== #
optimizer: sgd
lr: 0.256
#lr: 0.1
lr_policy: cosine_lr
warmup_length: 5

# ===== Network training config ===== #
epochs: 100
weight_decay: 0.000030517578125
#weight_decay: 0.0001
momentum: 0.875
batch_size: 256
label_smoothing: 0.1


# ===== Sparsity =========== #
conv_type: SubnetConvTiledFull
weight_tile_size: 130112
layer_mask_compression_factors: 1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,2

model_type: binarize
alpha_type: multiple
rerand_epoch_freq: 20
rerand_type: rerandomize_and_tile

data_type: float16

multigpu: 0,1,2,3,4,5,6,7
ngpus_per_node: 6



bn_type: NonAffineBatchNorm
#bn_type: LearnedBatchNorm
freeze_weights: True
prune_rate: -1 # Override1=2
weight_init: kaiming_normal
mode: fan_in
nonlinearity: relu
scale_fan: True



# ===== Hardware setup ===== #
workers: 20