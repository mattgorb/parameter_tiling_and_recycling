# Architecture
arch: FC

# ===== Dataset ===== #
data: /s/luffy/b/nobackup/mgorb/data
set: MNIST
name: fc_adam_baseline

# ===== Learning Rate Policy ======== #
optimizer: adam
lr: 0.0012

# ===== Network training config ===== #
epochs: 100
batch_size: 60

# ===== Sparsity =========== #
conv_type: DenseConv
bn_type: NonAffineBatchNorm

# ===== Hardware setup ===== #
workers: 4
log_dir: /s/luffy/b/nobackup/mgorb/data/runs/baseline