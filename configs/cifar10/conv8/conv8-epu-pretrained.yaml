# Architecture
arch: Conv8


# ===== Dataset ===== #
data: /s/babbage/b/nobackup/nblancha/public-datasets/subnetworks/data
set: CIFAR10
name: baseline

# ===== Learning Rate Policy ======== #
optimizer: sgd
lr: 0.1
lr_policy: cosine_lr

# ===== Network training config ===== #
epochs: 100
weight_decay: 0.0001
momentum: 0.9
batch_size: 128

# ===== Sparsity =========== #
#conv_type: SubnetConvEdgePopup
conv_type: DenseConv
bn_type: NonAffineBatchNorm
freeze_weights: True
prune_rate: -1
pretrained: /s/babbage/b/nobackup/nblancha/public-datasets/subnetworks/model_best.pth

weight_init: signed_constant
score_init: None
weight_seed: 0
score_seed: 0

gpu: 4
# ===== Hardware setup ===== #
workers: 4
