# Architecture
arch: Conv6

# ===== Dataset ===== #
#data: /s/luffy/b/nobackup/mgorb/data
data: /s/babbage/b/nobackup/nblancha/public-datasets/subnetworks/data
set: CIFAR10
name: baseline

# ===== Learning Rate Policy ======== #
optimizer: sgd
lr: 0.1
lr_policy: cosine_lr

# ===== Network training config ===== #
epochs: 250
weight_decay: 0.0001
momentum: 0.9
batch_size: 128

# ===== Sparsity =========== #
conv_type: SubnetConvBiprop
bn_type: NonAffineBatchNorm
freeze_weights: True

prune_rate: -1
rerand_epoch_freq: 10
rerand_rate: 0.2
rerand_type: recycle

weight_init: kaiming_normal
#scale_fan: True
score_init: None
weight_seed: 0
score_seed: 0



gpu: 3
# ===== Hardware setup ===== #
workers: 4
